{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tg_ltOnBMPwo"
   },
   "source": [
    "# Seq2Seqで文章生成\n",
    "文章生成向けにRNNを使用したSequence to Sequence（Seq2Seq）が有名です。 最近の研究ではこちらに対して、Attentionという機構を追加したりと話はすでに進んでいますが、まずは基礎的なSeq2Seqの流れを把握しておきましょう。\n",
    "\n",
    "Seq2Seqがこれまでの手法と大きく異なる点としては、入力が**可変長**、出力が**可変長**であることです。 そのため、固定長の入力から固定長の出力を得るような機械学習において、扱いずらい問題設定であることは明白です。\n",
    "\n",
    "また、実装上の問題にもなってくるのですが、基本的にはNumpyでは（サンプル数, 入力変数の数）という形式でデータが格納されている必要がありますが、文章の長さが異なることもあり、入力変数の数が各サンプル事で異なってしまい、Numpyの行列として格納することができません。 その問題を解決するために実装上では、`F.concat`をつかってうまくその問題を回避しているので、そういった点も注目してみてください。\n",
    "\n",
    "今回は[keras/examples](https://github.com/keras-team/keras/blob/master/examples/addition_rnn.py)にある`addition_rnn.py` をもとに解説を進めます。 すべての完璧なコードはこちらにあるため、この解説でざっくりと計算の流れをつかんでから、本格的なコードに進むと良いかと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqTBAhw-MPwp"
   },
   "source": [
    "## 必要なモジュールの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Q02DsL8MPwq"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htsmSni1MPwt"
   },
   "source": [
    "## データセットの作成\n",
    "\n",
    "今回は非常に簡単な問題設定ですが、`12+3`という文字列を入力すると、`15`という文字列が返ってくるような設定としましょう。\n",
    "果たして機械が足し算という規則性を再現することができるのかといった問題設定です。\n",
    "\n",
    "このインプットを日本語、アウトプットを英語にした場合は機械翻訳、インプットを質問、アウトプットを回答とした場合はチャットボットと呼ばれるものになります。\n",
    "\n",
    "まずは足し算のデータセットを作っていきましょう。\n",
    "実際の文章を適用する際のデータセットの形の参考になるため、どのような形式であるかをしっかり見ておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7IKC0djMPwu"
   },
   "outputs": [],
   "source": [
    "# シードの固定\n",
    "np.random.seed(1)\n",
    "\n",
    "# サンプル数5000\n",
    "x1 = np.random.randint(low=0, high=99, size=(5000,))\n",
    "x2 = np.random.randint(low=0, high=99, size=(5000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msTnCxpwMPww"
   },
   "outputs": [],
   "source": [
    "questions, expected = [], []\n",
    "for (_x1, _x2) in zip(x1, x2):\n",
    "    questions.append( '{}+{}'.format(_x1, _x2) )\n",
    "    expected.append( '{}'.format(_x1 + _x2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRGpsy0PMPwy"
   },
   "source": [
    "入力を`question`とし、出力を`expected`としましょう。\n",
    "では、作成した文字列を数値に変換していきます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vJX5V09MPwy"
   },
   "source": [
    "### IDに変換\n",
    "\n",
    "入力変数としては、単語単位で扱うのではなく、各単語に割り振られた要素番号（インデックス番号：ID）を使用します。\n",
    "単語（word）をIDに変換するため `word2id`、また最終的に元に戻すために `id2word` を下記のように作っておくと便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-EAos8QMPwz"
   },
   "outputs": [],
   "source": [
    "# 今回使用する文字列12種類\n",
    "chars = '0123456789+ '\n",
    "\n",
    "word2id = dict((c, i) for i, c in enumerate(chars))\n",
    "id2word = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AExxCpfrMPw1",
    "outputId": "e0993f3d-c35f-4143-ff71-3d4257d35e92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9,\n",
       " '+': 10,\n",
       " ' ': 11}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ffrFoxemMPw3",
    "outputId": "072a649e-dcaa-41c6-ce54-ba9770d5425c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0',\n",
       " 1: '1',\n",
       " 2: '2',\n",
       " 3: '3',\n",
       " 4: '4',\n",
       " 5: '5',\n",
       " 6: '6',\n",
       " 7: '7',\n",
       " 8: '8',\n",
       " 9: '9',\n",
       " 10: '+',\n",
       " 11: ' '}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-F6pUjlMPw5"
   },
   "source": [
    "では、作成したIDを元にデータを変換（エンコード）しましょう。`xs`, `ts`として入力と教師データをリストへまとめます。\n",
    "なぜ、これまで使用していた`x`と`t`でないかというと、固定長の場合は`x`と`t`で、それが可変長となった場合は`x`の`sequence`ということで`xs`や`ts`という風に名付けています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzjay8LFMPw6"
   },
   "source": [
    "入力`xs`に関しては2桁x2に+を加えて5桁になります。また教師データは2桁の足し算なので最大で3桁となります。\n",
    "それぞれの桁数に対して、IDの数だけ次元を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ut7GUlPMPw6",
    "outputId": "1d3fc9fe-5776-4fad-cc4a-e02efd1589d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs0 = np.zeros((5, 12))\n",
    "xs0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WilOXZS2MPw8",
    "outputId": "86e34cb0-7039-4240-f2bb-6ddf815348bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'37+78'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = questions[0]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gv3ERHAPMPw-"
   },
   "source": [
    "作成した`xs0`にIDを割り振ります。  \n",
    "まず`37+78`の先頭の値`3`のインデックスを表示しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03o5f98aMPw_",
    "outputId": "2fa9ef9d-f893-4657-be82-44053a35642f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id[sentence[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpJqLPOsMPxA"
   },
   "source": [
    "インデックスの対応する位置に`1`を割り当てます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOwiBWEgMPxB",
    "outputId": "ad89c3be-0d5a-4658-f189-b3311fd855fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs0[0, word2id[sentence[0]]] = 1 # numpyのインデックス\n",
    "xs0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dl7dVDp5MPxD"
   },
   "source": [
    "対応するインデックス位置に`1`が割り振られましたね。  \n",
    "このような形でIDの割り振りを繰り返していきます。\n",
    "\n",
    "### 演習\n",
    "では、先程までの流れを振り返りながら、   \n",
    "`37+78`をエンコードしていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KVS0sW4kMPxD"
   },
   "outputs": [],
   "source": [
    "for i, _c in enumerate(sentence):\n",
    "    xs0[i, word2id[_c]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ev7pniVpMPxG",
    "outputId": "6a864258-0051-403b-8b4e-8e25a871f4c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogQVB4A3MPxJ"
   },
   "source": [
    "エンコード関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90hlpnmlMPxK"
   },
   "outputs": [],
   "source": [
    "def encode(sentence, num_rows):\n",
    "    x = np.zeros((num_rows, 12))\n",
    "    for i, c in enumerate(sentence):\n",
    "        x[i, word2id[c]] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcF2WiKPMPxM"
   },
   "source": [
    "先ほどの例を確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xd7rYUJsMPxN",
    "outputId": "6798efa7-198d-4c8a-aed4-dc7a9ad2830b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(sentence, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCdaRUYUMPxP"
   },
   "source": [
    "では全体の5000サンプルのデータ作成を行いましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5djraGwhMPxQ",
    "outputId": "5c35392c-1cfe-4f6b-84df-e7a446825dc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 入力の最大長\n",
    "MAXLEN = 5\n",
    "# 入力の長さ\n",
    "DIGITS = 2\n",
    "\n",
    "# 入力の作成\n",
    "xs = np.zeros((len(questions), MAXLEN, len(chars)))\n",
    "\n",
    "# サンプル数、最大長、入力の種類\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pa5xMm-7MPxS"
   },
   "outputs": [],
   "source": [
    "xs = np.zeros((len(questions), MAXLEN, len(chars)))\n",
    "ts = np.zeros((len(expected), DIGITS + 1, len(chars)))\n",
    "for i, sentence in enumerate(questions):\n",
    "    xs[i] = encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    ts[i] = encode(sentence, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "impez5bUMPxW",
    "outputId": "3353ada6-c376-46e9-8745-f74f83a46d84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_P7AJACPMPxa",
    "outputId": "f5598246-2db3-44a0-a2f0-52059041b043"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 3, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "axugRuhuMPxd",
    "outputId": "9675f65d-058a-4175-dd98-86e4b2748c6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-cX5SkYVMPxe",
    "outputId": "64ddd23d-dd24-42b9-d8bf-6e09653d40a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7DqYbZ7dMPxg"
   },
   "source": [
    "## 訓練データと検証データに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n6l4lUlMPxh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練データと検証データの分割\n",
    "train_x, val_x, train_t, val_t = train_test_split(xs, ts, train_size=0.9,  test_size=0.1, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hObB7GCMMPxk",
    "outputId": "1628210e-570c-4c4c-ab7a-cf1c757b76f1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(4500, 5, 12)\n",
      "(4500, 3, 12)\n",
      "Validation Data:\n",
      "(500, 5, 12)\n",
      "(500, 3, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Training Data:')\n",
    "print(train_x.shape)\n",
    "print(train_t.shape)\n",
    "\n",
    "print('Validation Data:')\n",
    "print(val_x.shape)\n",
    "print(val_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SICGtcQfMPxl"
   },
   "source": [
    "## モデルの構築\n",
    "### モデルの定義（stateless）\n",
    "RNNはステートフル（stateful）であり、学習中にバッチ間で状態を維持することができます。ただしKerasのRNNはデフォルトではステートレス(stateless）であり、各バッチごとにモデル内部に保存してある隠れ状態をリセットしています（厳密にはステートレスとはモデルに状態を保持しないことをいう）。そのため明示的にステートフルに設定する必要があります。今回はその2通りの結果を比較しましょう。まず最初はデフォルトの設定である、ステートレスなモデルから学習を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ck3EruCZMPxm",
    "outputId": "a8c58279-6bf7-4f4b-952e-4d265faf16ce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4J-KC1_hMPxn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bJU7NYNvMPxp"
   },
   "source": [
    "NNの設計でこれまでとは異なる点はLSTM層を用いているところです。\n",
    "また`RepeatVector`および`TimeDistributed`をインポートしておく必要があります。\n",
    "`RepeatVector`とは、出力の最大シーケンス長分だけ入力を繰り返す処理を行い、\n",
    "`TimeDistributed`は時系列に沿って層を結合する処理を担っています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRhn4CuFMPxp"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import RepeatVector, TimeDistributed, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pvnl74UBMPxs"
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NDiL0XiwMPxv"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Encoder\n",
    "model.add(LSTM(HIDDEN_SIZE, input_shape=(5, 12)))\n",
    "\n",
    "# Decoder\n",
    "model.add(RepeatVector(DIGITS + 1))\n",
    "model.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(len(chars))))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "flaWVe84MPxw"
   },
   "outputs": [],
   "source": [
    "#  TensorBoardコールバックを作成する。\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "tbcb = TensorBoard(log_dir='./graph_seq2seq_stateless', histogram_freq=1, write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jzzTIrF8MPxy",
    "outputId": "6e6446f4-2c2f-4632-d907-146f71083f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 5s 1ms/sample - loss: 1.9183 - accuracy: 0.2445 - val_loss: 1.7166 - val_accuracy: 0.3933\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 64us/sample - loss: 1.6889 - accuracy: 0.2971 - val_loss: 1.6484 - val_accuracy: 0.3660\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 67us/sample - loss: 1.6492 - accuracy: 0.3504 - val_loss: 1.6282 - val_accuracy: 0.3813\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.6336 - accuracy: 0.3319 - val_loss: 1.6232 - val_accuracy: 0.2573\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.6184 - accuracy: 0.3419 - val_loss: 1.5981 - val_accuracy: 0.3600\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.5991 - accuracy: 0.3490 - val_loss: 1.5614 - val_accuracy: 0.2653\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.5715 - accuracy: 0.3298 - val_loss: 1.5321 - val_accuracy: 0.3607\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 1.5370 - accuracy: 0.3306 - val_loss: 1.4956 - val_accuracy: 0.4007\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.4918 - accuracy: 0.3738 - val_loss: 1.4533 - val_accuracy: 0.3060\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.4453 - accuracy: 0.3783 - val_loss: 1.4487 - val_accuracy: 0.2893\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.4139 - accuracy: 0.3881 - val_loss: 1.3680 - val_accuracy: 0.3873\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 69us/sample - loss: 1.3790 - accuracy: 0.3906 - val_loss: 1.3618 - val_accuracy: 0.3333\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 1.3502 - accuracy: 0.4170 - val_loss: 1.3231 - val_accuracy: 0.3560\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 69us/sample - loss: 1.3234 - accuracy: 0.4104 - val_loss: 1.2991 - val_accuracy: 0.3807\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 1.2897 - accuracy: 0.4333 - val_loss: 1.2863 - val_accuracy: 0.3800\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 67us/sample - loss: 1.2825 - accuracy: 0.4031 - val_loss: 1.2441 - val_accuracy: 0.4047\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 1.2683 - accuracy: 0.4074 - val_loss: 1.2859 - val_accuracy: 0.3553\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 1.2498 - accuracy: 0.4136 - val_loss: 1.2417 - val_accuracy: 0.3940\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 68us/sample - loss: 1.2384 - accuracy: 0.4104 - val_loss: 1.2169 - val_accuracy: 0.4447\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.2052 - accuracy: 0.4595 - val_loss: 1.2114 - val_accuracy: 0.5007\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.1892 - accuracy: 0.5057 - val_loss: 1.1953 - val_accuracy: 0.5173\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.1792 - accuracy: 0.5089 - val_loss: 1.2228 - val_accuracy: 0.4293\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 1.1827 - accuracy: 0.4827 - val_loss: 1.1540 - val_accuracy: 0.5700\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.1553 - accuracy: 0.5326 - val_loss: 1.1443 - val_accuracy: 0.5767\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.1612 - accuracy: 0.5121 - val_loss: 1.1766 - val_accuracy: 0.4893\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.1290 - accuracy: 0.5287 - val_loss: 1.1452 - val_accuracy: 0.5067\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 67us/sample - loss: 1.1392 - accuracy: 0.5189 - val_loss: 1.1165 - val_accuracy: 0.5107\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 64us/sample - loss: 1.0934 - accuracy: 0.5219 - val_loss: 1.1062 - val_accuracy: 0.5587\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 80us/sample - loss: 1.0750 - accuracy: 0.5706 - val_loss: 1.0792 - val_accuracy: 0.5160\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 68us/sample - loss: 1.0598 - accuracy: 0.5253 - val_loss: 1.0580 - val_accuracy: 0.5793\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 67us/sample - loss: 1.0484 - accuracy: 0.5727 - val_loss: 1.0455 - val_accuracy: 0.5447\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.0304 - accuracy: 0.5816 - val_loss: 1.0606 - val_accuracy: 0.5247\n",
      "Epoch 33/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 1.0494 - accuracy: 0.5544 - val_loss: 1.0256 - val_accuracy: 0.5860\n",
      "Epoch 34/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 1.0048 - accuracy: 0.5923 - val_loss: 1.0218 - val_accuracy: 0.5553\n",
      "Epoch 35/100\n",
      "4500/4500 [==============================] - 0s 64us/sample - loss: 1.0103 - accuracy: 0.5767 - val_loss: 1.0568 - val_accuracy: 0.5373\n",
      "Epoch 36/100\n",
      "4500/4500 [==============================] - 0s 68us/sample - loss: 1.0150 - accuracy: 0.5670 - val_loss: 0.9925 - val_accuracy: 0.5613\n",
      "Epoch 37/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.9950 - accuracy: 0.5682 - val_loss: 0.9896 - val_accuracy: 0.5867\n",
      "Epoch 38/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.9675 - accuracy: 0.5899 - val_loss: 0.9665 - val_accuracy: 0.5767\n",
      "Epoch 39/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.9504 - accuracy: 0.5836 - val_loss: 0.9604 - val_accuracy: 0.5987\n",
      "Epoch 40/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.9349 - accuracy: 0.5976 - val_loss: 0.9601 - val_accuracy: 0.5660\n",
      "Epoch 41/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.9230 - accuracy: 0.5970 - val_loss: 0.9300 - val_accuracy: 0.5673\n",
      "Epoch 42/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.9083 - accuracy: 0.5965 - val_loss: 0.9353 - val_accuracy: 0.5807\n",
      "Epoch 43/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.9075 - accuracy: 0.5897 - val_loss: 0.9196 - val_accuracy: 0.5787\n",
      "Epoch 44/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.8855 - accuracy: 0.6012 - val_loss: 0.8963 - val_accuracy: 0.5920\n",
      "Epoch 45/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.8780 - accuracy: 0.5990 - val_loss: 0.9249 - val_accuracy: 0.5720\n",
      "Epoch 46/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.8551 - accuracy: 0.6109 - val_loss: 0.8917 - val_accuracy: 0.5753\n",
      "Epoch 47/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.8458 - accuracy: 0.6075 - val_loss: 0.8600 - val_accuracy: 0.5920\n",
      "Epoch 48/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.8317 - accuracy: 0.6052 - val_loss: 0.8501 - val_accuracy: 0.6013\n",
      "Epoch 49/100\n",
      "4500/4500 [==============================] - 0s 69us/sample - loss: 0.8166 - accuracy: 0.6220 - val_loss: 0.8399 - val_accuracy: 0.6053\n",
      "Epoch 50/100\n",
      "4500/4500 [==============================] - 0s 69us/sample - loss: 0.7991 - accuracy: 0.6246 - val_loss: 0.8268 - val_accuracy: 0.6047\n",
      "Epoch 51/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.7823 - accuracy: 0.6279 - val_loss: 0.8132 - val_accuracy: 0.6080\n",
      "Epoch 52/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.7742 - accuracy: 0.6301 - val_loss: 0.8730 - val_accuracy: 0.5713\n",
      "Epoch 53/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.7659 - accuracy: 0.6327 - val_loss: 0.7701 - val_accuracy: 0.6340\n",
      "Epoch 54/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.7199 - accuracy: 0.6516 - val_loss: 0.7368 - val_accuracy: 0.6480\n",
      "Epoch 55/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.6998 - accuracy: 0.6632 - val_loss: 0.7294 - val_accuracy: 0.6527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.6845 - accuracy: 0.6684 - val_loss: 0.7228 - val_accuracy: 0.6293\n",
      "Epoch 57/100\n",
      "4500/4500 [==============================] - 0s 64us/sample - loss: 0.6666 - accuracy: 0.6704 - val_loss: 0.6845 - val_accuracy: 0.6660\n",
      "Epoch 58/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.6359 - accuracy: 0.6939 - val_loss: 0.6569 - val_accuracy: 0.6793\n",
      "Epoch 59/100\n",
      "4500/4500 [==============================] - 0s 67us/sample - loss: 0.6176 - accuracy: 0.6942 - val_loss: 0.6412 - val_accuracy: 0.6833\n",
      "Epoch 60/100\n",
      "4500/4500 [==============================] - 0s 67us/sample - loss: 0.5924 - accuracy: 0.7132 - val_loss: 0.6324 - val_accuracy: 0.6740\n",
      "Epoch 61/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.5752 - accuracy: 0.7155 - val_loss: 0.6070 - val_accuracy: 0.6933\n",
      "Epoch 62/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.5538 - accuracy: 0.7199 - val_loss: 0.6222 - val_accuracy: 0.6780\n",
      "Epoch 63/100\n",
      "4500/4500 [==============================] - 0s 68us/sample - loss: 0.5454 - accuracy: 0.7187 - val_loss: 0.5700 - val_accuracy: 0.7033\n",
      "Epoch 64/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.5147 - accuracy: 0.7359 - val_loss: 0.5599 - val_accuracy: 0.6940\n",
      "Epoch 65/100\n",
      "4500/4500 [==============================] - 0s 68us/sample - loss: 0.5040 - accuracy: 0.7386 - val_loss: 0.5372 - val_accuracy: 0.7160\n",
      "Epoch 66/100\n",
      "4500/4500 [==============================] - 0s 67us/sample - loss: 0.4787 - accuracy: 0.7481 - val_loss: 0.5122 - val_accuracy: 0.7200\n",
      "Epoch 67/100\n",
      "4500/4500 [==============================] - 0s 67us/sample - loss: 0.4614 - accuracy: 0.7527 - val_loss: 0.4992 - val_accuracy: 0.7387\n",
      "Epoch 68/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.4441 - accuracy: 0.7613 - val_loss: 0.4884 - val_accuracy: 0.7340\n",
      "Epoch 69/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.4275 - accuracy: 0.7639 - val_loss: 0.4754 - val_accuracy: 0.7253\n",
      "Epoch 70/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.4129 - accuracy: 0.7664 - val_loss: 0.4568 - val_accuracy: 0.7327\n",
      "Epoch 71/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.3969 - accuracy: 0.7774 - val_loss: 0.4382 - val_accuracy: 0.7460\n",
      "Epoch 72/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.3824 - accuracy: 0.7779 - val_loss: 0.4272 - val_accuracy: 0.7487\n",
      "Epoch 73/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.3708 - accuracy: 0.7839 - val_loss: 0.4188 - val_accuracy: 0.7473\n",
      "Epoch 74/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.3583 - accuracy: 0.7891 - val_loss: 0.3984 - val_accuracy: 0.7560\n",
      "Epoch 75/100\n",
      "4500/4500 [==============================] - 0s 64us/sample - loss: 0.3442 - accuracy: 0.7949 - val_loss: 0.3960 - val_accuracy: 0.7493\n",
      "Epoch 76/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.3318 - accuracy: 0.7962 - val_loss: 0.3793 - val_accuracy: 0.7660\n",
      "Epoch 77/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.3199 - accuracy: 0.8044 - val_loss: 0.3680 - val_accuracy: 0.7713\n",
      "Epoch 78/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.3096 - accuracy: 0.8031 - val_loss: 0.3572 - val_accuracy: 0.7647\n",
      "Epoch 79/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.2971 - accuracy: 0.8082 - val_loss: 0.3601 - val_accuracy: 0.7560\n",
      "Epoch 80/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.3006 - accuracy: 0.8003 - val_loss: 0.3403 - val_accuracy: 0.7733\n",
      "Epoch 81/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.2837 - accuracy: 0.8072 - val_loss: 0.3407 - val_accuracy: 0.7780\n",
      "Epoch 82/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.2720 - accuracy: 0.8139 - val_loss: 0.3223 - val_accuracy: 0.7780\n",
      "Epoch 83/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.2607 - accuracy: 0.8142 - val_loss: 0.3146 - val_accuracy: 0.7780\n",
      "Epoch 84/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.2580 - accuracy: 0.8144 - val_loss: 0.3186 - val_accuracy: 0.7773\n",
      "Epoch 85/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.2477 - accuracy: 0.8168 - val_loss: 0.3277 - val_accuracy: 0.7627\n",
      "Epoch 86/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.2447 - accuracy: 0.8166 - val_loss: 0.2855 - val_accuracy: 0.7887\n",
      "Epoch 87/100\n",
      "4500/4500 [==============================] - 0s 68us/sample - loss: 0.2422 - accuracy: 0.8139 - val_loss: 0.2882 - val_accuracy: 0.7840\n",
      "Epoch 88/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.2248 - accuracy: 0.8243 - val_loss: 0.2686 - val_accuracy: 0.7947\n",
      "Epoch 89/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.2111 - accuracy: 0.8272 - val_loss: 0.2706 - val_accuracy: 0.7827\n",
      "Epoch 90/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.2050 - accuracy: 0.8293 - val_loss: 0.2518 - val_accuracy: 0.7980\n",
      "Epoch 91/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.1939 - accuracy: 0.8338 - val_loss: 0.2519 - val_accuracy: 0.8007\n",
      "Epoch 92/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.1918 - accuracy: 0.8329 - val_loss: 0.2511 - val_accuracy: 0.7867\n",
      "Epoch 93/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.1856 - accuracy: 0.8349 - val_loss: 0.2346 - val_accuracy: 0.8020\n",
      "Epoch 94/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.1830 - accuracy: 0.8355 - val_loss: 0.2380 - val_accuracy: 0.7993\n",
      "Epoch 95/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.1963 - accuracy: 0.8250 - val_loss: 0.2487 - val_accuracy: 0.7887\n",
      "Epoch 96/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.1747 - accuracy: 0.8345 - val_loss: 0.2397 - val_accuracy: 0.7960\n",
      "Epoch 97/100\n",
      "4500/4500 [==============================] - 0s 65us/sample - loss: 0.1827 - accuracy: 0.8281 - val_loss: 0.2232 - val_accuracy: 0.8000\n",
      "Epoch 98/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.1624 - accuracy: 0.8366 - val_loss: 0.2271 - val_accuracy: 0.7900\n",
      "Epoch 99/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.1560 - accuracy: 0.8386 - val_loss: 0.2128 - val_accuracy: 0.8007\n",
      "Epoch 100/100\n",
      "4500/4500 [==============================] - 0s 66us/sample - loss: 0.1481 - accuracy: 0.8384 - val_loss: 0.1992 - val_accuracy: 0.8020\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_t,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=100,\n",
    "                  validation_data=(val_x, val_t),\n",
    "                  callbacks=[tbcb])\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Va8TIMhRMPx0"
   },
   "source": [
    "### モデルの定義（stateful）\n",
    "ステートフルモデルを用いる際に注意すべき点が3点あります。\n",
    "* データの周期性を反映したバッチサイズ\n",
    "* エポック数だけfor文のループを回す\n",
    "* データを順番に入力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtWh59ewMPx1"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_SIZE, stateful=True,\n",
    "                   batch_input_shape=(BATCH_SIZE, MAXLEN, len(chars)),\n",
    "                   return_sequences=False))\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "\n",
    "for _ in range(5):\n",
    "    model.add(LSTM(HIDDEN_SIZE, return_sequences=True))\n",
    "\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pGJpi_YeMPx3"
   },
   "outputs": [],
   "source": [
    "train_size = (train_x.shape[0] // BATCH_SIZE) * BATCH_SIZE\n",
    "test_size = (val_x.shape[0] // BATCH_SIZE) * BATCH_SIZE\n",
    "train_x, train_t = train_x[:train_size], train_t[:train_size]\n",
    "val_x, val_t = val_x[:test_size], val_t[:test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "16cqOyayMPx4",
    "outputId": "bd1f8d77-1854-4fbc-8b61-85046b762e42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 11s 3ms/sample - loss: 1.9860 - accuracy: 0.2482 - val_loss: 1.8280 - val_accuracy: 0.2179\n",
      "Epoch 2 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.7362 - accuracy: 0.2420 - val_loss: 1.6912 - val_accuracy: 0.2344\n",
      "Epoch 3 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6983 - accuracy: 0.2620 - val_loss: 1.6907 - val_accuracy: 0.2153\n",
      "Epoch 4 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 160us/sample - loss: 1.6945 - accuracy: 0.2269 - val_loss: 1.6921 - val_accuracy: 0.2153\n",
      "Epoch 5 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6943 - accuracy: 0.2385 - val_loss: 1.6884 - val_accuracy: 0.4002\n",
      "Epoch 6 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6920 - accuracy: 0.3119 - val_loss: 1.6793 - val_accuracy: 0.4002\n",
      "Epoch 7 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.6929 - accuracy: 0.2629 - val_loss: 1.6838 - val_accuracy: 0.4002\n",
      "Epoch 8 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6915 - accuracy: 0.2731 - val_loss: 1.6827 - val_accuracy: 0.2248\n",
      "Epoch 9 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6921 - accuracy: 0.2736 - val_loss: 1.6866 - val_accuracy: 0.2196\n",
      "Epoch 10 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6926 - accuracy: 0.2831 - val_loss: 1.6843 - val_accuracy: 0.4002\n",
      "Epoch 11 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 161us/sample - loss: 1.6919 - accuracy: 0.3047 - val_loss: 1.6817 - val_accuracy: 0.4002\n",
      "Epoch 12 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6917 - accuracy: 0.2717 - val_loss: 1.6828 - val_accuracy: 0.2248\n",
      "Epoch 13 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6919 - accuracy: 0.2816 - val_loss: 1.6862 - val_accuracy: 0.4002\n",
      "Epoch 14 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6907 - accuracy: 0.2753 - val_loss: 1.6841 - val_accuracy: 0.2153\n",
      "Epoch 15 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6920 - accuracy: 0.2507 - val_loss: 1.6802 - val_accuracy: 0.2153\n",
      "Epoch 16 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6910 - accuracy: 0.2902 - val_loss: 1.6828 - val_accuracy: 0.4002\n",
      "Epoch 17 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6913 - accuracy: 0.3054 - val_loss: 1.6814 - val_accuracy: 0.4002\n",
      "Epoch 18 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6914 - accuracy: 0.2836 - val_loss: 1.6853 - val_accuracy: 0.4002\n",
      "Epoch 19 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 160us/sample - loss: 1.6922 - accuracy: 0.2952 - val_loss: 1.6796 - val_accuracy: 0.2179\n",
      "Epoch 20 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6911 - accuracy: 0.2308 - val_loss: 1.6836 - val_accuracy: 0.2196\n",
      "Epoch 21 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6913 - accuracy: 0.2728 - val_loss: 1.6808 - val_accuracy: 0.4002\n",
      "Epoch 22 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6918 - accuracy: 0.3074 - val_loss: 1.6803 - val_accuracy: 0.4002\n",
      "Epoch 23 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6966 - accuracy: 0.3033 - val_loss: 1.6842 - val_accuracy: 0.4002\n",
      "Epoch 24 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6916 - accuracy: 0.3120 - val_loss: 1.6822 - val_accuracy: 0.2292\n",
      "Epoch 25 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.6913 - accuracy: 0.2335 - val_loss: 1.6836 - val_accuracy: 0.4002\n",
      "Epoch 26 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6909 - accuracy: 0.3202 - val_loss: 1.6818 - val_accuracy: 0.2248\n",
      "Epoch 27 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 156us/sample - loss: 1.6915 - accuracy: 0.2758 - val_loss: 1.6821 - val_accuracy: 0.2248\n",
      "Epoch 28 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6903 - accuracy: 0.2446 - val_loss: 1.6838 - val_accuracy: 0.2292\n",
      "Epoch 29 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6908 - accuracy: 0.3008 - val_loss: 1.6857 - val_accuracy: 0.2248\n",
      "Epoch 30 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.6914 - accuracy: 0.3315 - val_loss: 1.6814 - val_accuracy: 0.4002\n",
      "Epoch 31 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6906 - accuracy: 0.2377 - val_loss: 1.6818 - val_accuracy: 0.2292\n",
      "Epoch 32 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 160us/sample - loss: 1.6907 - accuracy: 0.2724 - val_loss: 1.6836 - val_accuracy: 0.4002\n",
      "Epoch 33 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6913 - accuracy: 0.2800 - val_loss: 1.6844 - val_accuracy: 0.4002\n",
      "Epoch 34 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6905 - accuracy: 0.2885 - val_loss: 1.6813 - val_accuracy: 0.2248\n",
      "Epoch 35 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6905 - accuracy: 0.3182 - val_loss: 1.6820 - val_accuracy: 0.2248\n",
      "Epoch 36 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6906 - accuracy: 0.2292 - val_loss: 1.6816 - val_accuracy: 0.4002\n",
      "Epoch 37 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6907 - accuracy: 0.3092 - val_loss: 1.6828 - val_accuracy: 0.2292\n",
      "Epoch 38 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6901 - accuracy: 0.2482 - val_loss: 1.6836 - val_accuracy: 0.4002\n",
      "Epoch 39 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6906 - accuracy: 0.2749 - val_loss: 1.6836 - val_accuracy: 0.4002\n",
      "Epoch 40 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 160us/sample - loss: 1.6894 - accuracy: 0.3047 - val_loss: 1.6812 - val_accuracy: 0.2248\n",
      "Epoch 41 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6897 - accuracy: 0.3082 - val_loss: 1.6805 - val_accuracy: 0.2248\n",
      "Epoch 42 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6899 - accuracy: 0.2739 - val_loss: 1.6832 - val_accuracy: 0.2248\n",
      "Epoch 43 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6894 - accuracy: 0.2360 - val_loss: 1.6837 - val_accuracy: 0.2248\n",
      "Epoch 44 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.6897 - accuracy: 0.3051 - val_loss: 1.6797 - val_accuracy: 0.2248\n",
      "Epoch 45 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6902 - accuracy: 0.2539 - val_loss: 1.6824 - val_accuracy: 0.4002\n",
      "Epoch 46 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6893 - accuracy: 0.2911 - val_loss: 1.6817 - val_accuracy: 0.4002\n",
      "Epoch 47 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6906 - accuracy: 0.3817 - val_loss: 1.6799 - val_accuracy: 0.2248\n",
      "Epoch 48 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.6871 - accuracy: 0.2363 - val_loss: 1.6894 - val_accuracy: 0.2309\n",
      "Epoch 49 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6824 - accuracy: 0.3107 - val_loss: 1.6818 - val_accuracy: 0.4002\n",
      "Epoch 50 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.6468 - accuracy: 0.3198 - val_loss: 1.6271 - val_accuracy: 0.4002\n",
      "Epoch 51 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.6099 - accuracy: 0.3868 - val_loss: 1.5673 - val_accuracy: 0.3845\n",
      "Epoch 52 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.5391 - accuracy: 0.3967 - val_loss: 1.4763 - val_accuracy: 0.3941\n",
      "Epoch 53 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.4447 - accuracy: 0.3829 - val_loss: 1.3700 - val_accuracy: 0.4184\n",
      "Epoch 54 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.3502 - accuracy: 0.3833 - val_loss: 1.2734 - val_accuracy: 0.3984\n",
      "Epoch 55 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.2745 - accuracy: 0.3922 - val_loss: 1.2600 - val_accuracy: 0.4149\n",
      "Epoch 56 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.2120 - accuracy: 0.4199 - val_loss: 1.2069 - val_accuracy: 0.4167\n",
      "Epoch 57 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.1780 - accuracy: 0.4680 - val_loss: 1.1051 - val_accuracy: 0.4887\n",
      "Epoch 58 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.1156 - accuracy: 0.4529 - val_loss: 1.0978 - val_accuracy: 0.4913\n",
      "Epoch 59 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 1.2443 - accuracy: 0.3893 - val_loss: 1.0892 - val_accuracy: 0.5616\n",
      "Epoch 60 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 162us/sample - loss: 1.0891 - accuracy: 0.5202 - val_loss: 1.0475 - val_accuracy: 0.5165\n",
      "Epoch 61 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.0600 - accuracy: 0.5214 - val_loss: 1.0112 - val_accuracy: 0.5191\n",
      "Epoch 62 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.0392 - accuracy: 0.5064 - val_loss: 0.9901 - val_accuracy: 0.5356\n",
      "Epoch 63 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.0314 - accuracy: 0.5141 - val_loss: 0.9962 - val_accuracy: 0.5009\n",
      "Epoch 64 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 1.0030 - accuracy: 0.5190 - val_loss: 0.9565 - val_accuracy: 0.5495\n",
      "Epoch 65 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 1.0202 - accuracy: 0.5141 - val_loss: 0.9576 - val_accuracy: 0.5165\n",
      "Epoch 66 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.9919 - accuracy: 0.5166 - val_loss: 0.9551 - val_accuracy: 0.5069\n",
      "Epoch 67 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.9396 - accuracy: 0.5365 - val_loss: 0.9303 - val_accuracy: 0.5330\n",
      "Epoch 68 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.9451 - accuracy: 0.5280 - val_loss: 0.9313 - val_accuracy: 0.5017\n",
      "Epoch 69 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 156us/sample - loss: 0.9926 - accuracy: 0.4990 - val_loss: 0.9263 - val_accuracy: 0.5130\n",
      "Epoch 70 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.9017 - accuracy: 0.5622 - val_loss: 0.8861 - val_accuracy: 0.5286\n",
      "Epoch 71 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.8786 - accuracy: 0.5574 - val_loss: 0.8590 - val_accuracy: 0.5590\n",
      "Epoch 72 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 160us/sample - loss: 0.9152 - accuracy: 0.5519 - val_loss: 0.8843 - val_accuracy: 0.5252\n",
      "Epoch 73 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.8912 - accuracy: 0.5469 - val_loss: 0.8855 - val_accuracy: 0.5365\n",
      "Epoch 74 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.9119 - accuracy: 0.5372 - val_loss: 0.8507 - val_accuracy: 0.5530\n",
      "Epoch 75 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.8929 - accuracy: 0.5458 - val_loss: 0.8612 - val_accuracy: 0.5321\n",
      "Epoch 76 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.8415 - accuracy: 0.5688 - val_loss: 0.8121 - val_accuracy: 0.5564\n",
      "Epoch 77 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.8224 - accuracy: 0.5780 - val_loss: 0.8233 - val_accuracy: 0.5495\n",
      "Epoch 78 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.8197 - accuracy: 0.5722 - val_loss: 0.7836 - val_accuracy: 0.5747\n",
      "Epoch 79 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 171us/sample - loss: 0.8916 - accuracy: 0.5531 - val_loss: 0.7925 - val_accuracy: 0.5781\n",
      "Epoch 80 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.8888 - accuracy: 0.5446 - val_loss: 0.7918 - val_accuracy: 0.5781\n",
      "Epoch 81 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.7903 - accuracy: 0.5887 - val_loss: 0.7725 - val_accuracy: 0.5885\n",
      "Epoch 82 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.7978 - accuracy: 0.5933 - val_loss: 0.7867 - val_accuracy: 0.5764\n",
      "Epoch 83 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.7733 - accuracy: 0.5981 - val_loss: 0.7979 - val_accuracy: 0.5842\n",
      "Epoch 84 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.7716 - accuracy: 0.6032 - val_loss: 0.7252 - val_accuracy: 0.6024\n",
      "Epoch 85 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 0.7895 - accuracy: 0.5897 - val_loss: 0.7603 - val_accuracy: 0.6085\n",
      "Epoch 86 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 156us/sample - loss: 0.7878 - accuracy: 0.5943 - val_loss: 0.7865 - val_accuracy: 0.5981\n",
      "Epoch 87 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 155us/sample - loss: 0.7659 - accuracy: 0.6027 - val_loss: 0.6794 - val_accuracy: 0.6432\n",
      "Epoch 88 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 0.7673 - accuracy: 0.5995 - val_loss: 0.7129 - val_accuracy: 0.6050\n",
      "Epoch 89 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.7821 - accuracy: 0.5977 - val_loss: 0.7061 - val_accuracy: 0.6233\n",
      "Epoch 90 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.7317 - accuracy: 0.6172 - val_loss: 0.6976 - val_accuracy: 0.6398\n",
      "Epoch 91 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.7530 - accuracy: 0.6032 - val_loss: 0.6805 - val_accuracy: 0.6285\n",
      "Epoch 92 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 160us/sample - loss: 0.7350 - accuracy: 0.6140 - val_loss: 0.6885 - val_accuracy: 0.6328\n",
      "Epoch 93 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.7904 - accuracy: 0.5953 - val_loss: 0.7061 - val_accuracy: 0.6224\n",
      "Epoch 94 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.7618 - accuracy: 0.6056 - val_loss: 0.7089 - val_accuracy: 0.6163\n",
      "Epoch 95 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 156us/sample - loss: 0.7278 - accuracy: 0.6153 - val_loss: 0.6943 - val_accuracy: 0.6146\n",
      "Epoch 96 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.8033 - accuracy: 0.5922 - val_loss: 0.7081 - val_accuracy: 0.6059\n",
      "Epoch 97 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 159us/sample - loss: 0.6863 - accuracy: 0.6404 - val_loss: 0.6498 - val_accuracy: 0.6615\n",
      "Epoch 98 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.7658 - accuracy: 0.6049 - val_loss: 0.6673 - val_accuracy: 0.6476\n",
      "Epoch 99 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 158us/sample - loss: 0.6791 - accuracy: 0.6400 - val_loss: 0.6541 - val_accuracy: 0.6554\n",
      "Epoch 100 / 100\n",
      "Train on 4480 samples, validate on 384 samples\n",
      "4480/4480 [==============================] - 1s 157us/sample - loss: 0.6717 - accuracy: 0.6446 - val_loss: 0.6299 - val_accuracy: 0.6597\n"
     ]
    }
   ],
   "source": [
    "tbcb = TensorBoard(log_dir='./graph_seq2seq_stateful', histogram_freq=1, write_graph=True)\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "for i in range(NUM_EPOCHS):\n",
    "    print(\"Epoch {:d} / {:d}\".format(i + 1, NUM_EPOCHS))\n",
    "    model.fit(train_x, train_t,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=1,\n",
    "                      validation_data=(val_x, val_t))\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jaTshHovMPx6"
   },
   "source": [
    "## 結果の確認\n",
    "10題ほどランダムに問題を出してその結果を観察しましょう。\n",
    "まずランダムに検証用のデータからランダムにidを選びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_ZJ4G1hMPx6",
    "outputId": "7ac0d8c1-04a2-4c02-9885-851b9a88ec64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.random.randint(0, len(val_x))\n",
    "ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DANJit45MPx8"
   },
   "source": [
    "続いてidに対応する`x`と`t`を`rowx`と`rowt`とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1zUbrkdMPx8",
    "outputId": "608319c8-ffe7-4769-8073-85c25d70a5c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowx, rowt = val_x, val_t\n",
    "rowx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ht8qWsQMPx-",
    "outputId": "c1e95dec-7393-440e-be8e-f910944114e3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zJWRddAcMPyA"
   },
   "source": [
    "入力`rowx`に対して`model.predict_classes()`とすると予測結果がidで返ってきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJT2yHfVMPyB",
    "outputId": "7bd93349-6cec-4742-93b5-a2c87b74736f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 2],\n",
       "       [9, 0, 0],\n",
       "       [9, 7, 0],\n",
       "       ...,\n",
       "       [9, 9, 0],\n",
       "       [8, 3, 1],\n",
       "       [9, 6, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict_classes(rowx, batch_size=128 ,verbose=0)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2XergJOMPyD"
   },
   "source": [
    "デコード関数を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5k3e2m_MPyE"
   },
   "outputs": [],
   "source": [
    "def decode(x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(id2word[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tLcNJscAMPyF",
    "outputId": "3b532969-81f4-4af8-fb80-ff356a866d5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'45+79'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = decode(rowx[0])\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYLsLIKrMPyH",
    "outputId": "8377eb38-0ea9-4e27-9b33-abec656bd02e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'124'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = decode(rowt[0])\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ta174sjwMPyJ",
    "outputId": "39fea22f-cb12-4163-e4a9-574cb003d55c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'122'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = decode(preds[0], calc_argmax=False)\n",
    "guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64+28'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = decode(rowx[1])\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'920'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = decode(rowt[1])\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'910'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = decode(preds[1], calc_argmax=False)\n",
    "guess"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "11_Keras_Seq2Seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
