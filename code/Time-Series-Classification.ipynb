{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader.yahoo.daily import YahooDailyReader\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_st = datetime.datetime(2015, 1, 1)\n",
    "date_fn = datetime.datetime(2020,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>47.439999</td>\n",
       "      <td>46.450001</td>\n",
       "      <td>46.730000</td>\n",
       "      <td>46.450001</td>\n",
       "      <td>21552500.0</td>\n",
       "      <td>41.587284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>47.419998</td>\n",
       "      <td>46.540001</td>\n",
       "      <td>46.660000</td>\n",
       "      <td>46.759998</td>\n",
       "      <td>27913900.0</td>\n",
       "      <td>41.864841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>46.730000</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>46.369999</td>\n",
       "      <td>46.330002</td>\n",
       "      <td>39673900.0</td>\n",
       "      <td>41.479866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       High        Low       Open      Close      Volume  \\\n",
       "0 2014-12-31  47.439999  46.450001  46.730000  46.450001  21552500.0   \n",
       "1 2015-01-02  47.419998  46.540001  46.660000  46.759998  27913900.0   \n",
       "2 2015-01-05  46.730000  46.250000  46.369999  46.330002  39673900.0   \n",
       "\n",
       "   Adj Close  \n",
       "0  41.587284  \n",
       "1  41.864841  \n",
       "2  41.479866  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = YahooDailyReader('MSFT', date_st, date_fn).read().reset_index()\n",
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = df1['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 46.45000076,  46.75999832,  46.33000183, ..., 158.96000671,\n",
       "       157.58999634, 157.69999695])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題設定\n",
    "- 分類問題\n",
    "- 株価について、分類したい。\\\n",
    "- ある日から見て、次の日の株価があがるか下がるかを予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 教師データの作成\n",
    "- 演習\n",
    "\n",
    "    - ある日の数値を入力データx\n",
    "    - 明日の株価（終値）があがるか下がるかを予測したいので、上がる場合は「１」、ｓがる場合は「０」をラベリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.45000076293945"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[0]<ts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t, = [], [],\n",
    "for i in range(len(ts)-1):\n",
    "    x.append(ts[i])\n",
    "    if ts[i-1]<ts[i]:\n",
    "        t.append(1)\n",
    "    else:\n",
    "        t.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array(t)\n",
    "x = np.array(x).reshape(len(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 1)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練データと検証データへの分割\n",
    " - 訓練データ70%\n",
    " - train_size=1,shuffle = False : ランダムに選ばないようにする. train test splitの時\n",
    "### モデルの構築・学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 訓練データと検証データに切り分け\n",
    "train_x, val_x, train_t, val_t = train_test_split(x, t, train_size=0.7, random_state=0, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((880, 1), (378, 1), (880,), (378,))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, val_x.shape, train_t.shape, val_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シードの固定\n",
    "import os\n",
    "import random\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    random.seed(seed) #　random関数のシードを固定\n",
    "    np.random.seed(seed) #numpyのシードを固定\n",
    "    tf.random.set_seed(seed) #tensorflowのシードを固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models,layers\n",
    "\n",
    "#シードの固定\n",
    "reset_seed(0)\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(10, input_shape=(1,), activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer) #ここでオプティマイザと損失関数\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 880 samples, validate on 378 samples\n",
      "Epoch 1/20\n",
      "880/880 [==============================] - 0s 518us/sample - loss: 8.5695 - accuracy: 0.4943 - val_loss: 10.1153 - val_accuracy: 0.5714\n",
      "Epoch 2/20\n",
      "880/880 [==============================] - 0s 34us/sample - loss: 1.2867 - accuracy: 0.4920 - val_loss: 1.2377 - val_accuracy: 0.5714\n",
      "Epoch 3/20\n",
      "880/880 [==============================] - 0s 32us/sample - loss: 0.7155 - accuracy: 0.5034 - val_loss: 0.8645 - val_accuracy: 0.5714\n",
      "Epoch 4/20\n",
      "880/880 [==============================] - 0s 32us/sample - loss: 0.7021 - accuracy: 0.5011 - val_loss: 0.7391 - val_accuracy: 0.5714\n",
      "Epoch 5/20\n",
      "880/880 [==============================] - 0s 32us/sample - loss: 0.6973 - accuracy: 0.5125 - val_loss: 0.7017 - val_accuracy: 0.5714\n",
      "Epoch 6/20\n",
      "880/880 [==============================] - 0s 33us/sample - loss: 0.6954 - accuracy: 0.5125 - val_loss: 0.6876 - val_accuracy: 0.5714\n",
      "Epoch 7/20\n",
      "880/880 [==============================] - 0s 32us/sample - loss: 0.6944 - accuracy: 0.5125 - val_loss: 0.6826 - val_accuracy: 0.5714\n",
      "Epoch 8/20\n",
      "880/880 [==============================] - 0s 33us/sample - loss: 0.6938 - accuracy: 0.5125 - val_loss: 0.6818 - val_accuracy: 0.5714\n",
      "Epoch 9/20\n",
      "880/880 [==============================] - 0s 37us/sample - loss: 0.6933 - accuracy: 0.5125 - val_loss: 0.6833 - val_accuracy: 0.5714\n",
      "Epoch 10/20\n",
      "880/880 [==============================] - 0s 34us/sample - loss: 0.6931 - accuracy: 0.5125 - val_loss: 0.6860 - val_accuracy: 0.5714\n",
      "Epoch 11/20\n",
      "880/880 [==============================] - 0s 32us/sample - loss: 0.6929 - accuracy: 0.5125 - val_loss: 0.6894 - val_accuracy: 0.5714\n",
      "Epoch 12/20\n",
      "880/880 [==============================] - 0s 36us/sample - loss: 0.6927 - accuracy: 0.5318 - val_loss: 0.6931 - val_accuracy: 0.4974\n",
      "Epoch 13/20\n",
      "880/880 [==============================] - 0s 33us/sample - loss: 0.6926 - accuracy: 0.5295 - val_loss: 0.6969 - val_accuracy: 0.4286\n",
      "Epoch 14/20\n",
      "880/880 [==============================] - 0s 32us/sample - loss: 0.6926 - accuracy: 0.5250 - val_loss: 0.7006 - val_accuracy: 0.4286\n",
      "Epoch 15/20\n",
      "880/880 [==============================] - 0s 33us/sample - loss: 0.6925 - accuracy: 0.5170 - val_loss: 0.7042 - val_accuracy: 0.4286\n",
      "Epoch 16/20\n",
      "880/880 [==============================] - 0s 33us/sample - loss: 0.6925 - accuracy: 0.5148 - val_loss: 0.7074 - val_accuracy: 0.4286\n",
      "Epoch 17/20\n",
      "880/880 [==============================] - 0s 32us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.7103 - val_accuracy: 0.4286\n",
      "Epoch 18/20\n",
      "880/880 [==============================] - 0s 33us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.7127 - val_accuracy: 0.4286\n",
      "Epoch 19/20\n",
      "880/880 [==============================] - 0s 32us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.7145 - val_accuracy: 0.4286\n",
      "Epoch 20/20\n",
      "880/880 [==============================] - 0s 34us/sample - loss: 0.6927 - accuracy: 0.5148 - val_loss: 0.7159 - val_accuracy: 0.4286\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_t,\n",
    "          batch_size=100,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(val_x, val_t),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.569455</td>\n",
       "      <td>0.494318</td>\n",
       "      <td>10.115261</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.286716</td>\n",
       "      <td>0.492045</td>\n",
       "      <td>1.237701</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.715520</td>\n",
       "      <td>0.503409</td>\n",
       "      <td>0.864524</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.702097</td>\n",
       "      <td>0.501136</td>\n",
       "      <td>0.739087</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.697309</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.701724</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.695421</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.687587</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.694398</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.682553</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.693765</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.681802</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.693345</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.683286</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.693057</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.685996</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.689376</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.692719</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>0.693085</td>\n",
       "      <td>0.497355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.692629</td>\n",
       "      <td>0.529545</td>\n",
       "      <td>0.696896</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.692574</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.700644</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.692548</td>\n",
       "      <td>0.517045</td>\n",
       "      <td>0.704194</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.692544</td>\n",
       "      <td>0.514773</td>\n",
       "      <td>0.707441</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.692558</td>\n",
       "      <td>0.514773</td>\n",
       "      <td>0.710293</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.692585</td>\n",
       "      <td>0.514773</td>\n",
       "      <td>0.712680</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.692621</td>\n",
       "      <td>0.514773</td>\n",
       "      <td>0.714545</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.692663</td>\n",
       "      <td>0.514773</td>\n",
       "      <td>0.715856</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy   val_loss  val_accuracy\n",
       "0   8.569455  0.494318  10.115261      0.571429\n",
       "1   1.286716  0.492045   1.237701      0.571429\n",
       "2   0.715520  0.503409   0.864524      0.571429\n",
       "3   0.702097  0.501136   0.739087      0.571429\n",
       "4   0.697309  0.512500   0.701724      0.571429\n",
       "5   0.695421  0.512500   0.687587      0.571429\n",
       "6   0.694398  0.512500   0.682553      0.571429\n",
       "7   0.693765  0.512500   0.681802      0.571429\n",
       "8   0.693345  0.512500   0.683286      0.571429\n",
       "9   0.693057  0.512500   0.685996      0.571429\n",
       "10  0.692857  0.512500   0.689376      0.571429\n",
       "11  0.692719  0.531818   0.693085      0.497355\n",
       "12  0.692629  0.529545   0.696896      0.428571\n",
       "13  0.692574  0.525000   0.700644      0.428571\n",
       "14  0.692548  0.517045   0.704194      0.428571\n",
       "15  0.692544  0.514773   0.707441      0.428571\n",
       "16  0.692558  0.514773   0.710293      0.428571\n",
       "17  0.692585  0.514773   0.712680      0.428571\n",
       "18  0.692621  0.514773   0.714545      0.428571\n",
       "19  0.692663  0.514773   0.715856      0.428571"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = results[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_shape=(1,1)知雨風に二次元の形になる。\n",
    "\n",
    "x = np.array(x).reshape(len(x), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 1, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, val_x, train_t, val_t = train_test_split(x, t, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    random.seed(seed) #　random関数のシードを固定\n",
    "    np.random.seed(seed) #numpyのシードを固定\n",
    "    tf.random.set_seed(seed) #tensorflowのシードを固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#シードの固定\n",
    "reset_seed(0)\n",
    "#モデルのインスタンス化\n",
    "model = models.Sequential()\n",
    "\n",
    "#モデルの構築\n",
    "model.add(layers.LSTM(10, activation='relu', input_shape=(1,1)))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法設定\n",
    "optimizer = keras.optimizers.SGD(lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのコンパイル\n",
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "            optimizer = optimizer,\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_2_input to have 3 dimensions, but got array with shape (880, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-551a531ab997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m           shuffle=False)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    563\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_2_input to have 3 dimensions, but got array with shape (880, 1)"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_t,\n",
    "          batch_size=100,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_data=(val_x, val_t),\n",
    "          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
